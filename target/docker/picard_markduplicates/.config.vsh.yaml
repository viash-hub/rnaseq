functionality:
  name: "picard_markduplicates"
  version: "dev"
  arguments:
  - type: "file"
    name: "--bam"
    description: "Input BAM file"
    info: null
    must_exist: true
    create_parent: true
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--fasta"
    description: "Reference genome FASTA file"
    info: null
    must_exist: true
    create_parent: true
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--fai"
    description: "Reference genome FASTA index"
    info: null
    must_exist: true
    create_parent: true
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "string"
    name: "--extra_picard_args"
    description: "Additional argument to be passed to Picard MarkDuplicates"
    info: null
    default:
    - "--ASSUME_SORTED true --REMOVE_DUPLICATES false --VALIDATION_STRINGENCY LENIENT\
      \ --TMP_DIR tmp"
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--output_bam"
    description: "BAM file with duplicate reads marked/removed"
    info: null
    default:
    - "$id.MarkDuplicates.bam"
    must_exist: true
    create_parent: true
    required: false
    direction: "output"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--bai"
    description: "An optional BAM index file. If desired, --CREATE_INDEX must be passed\
      \ as a flag"
    info: null
    default:
    - "$id.MarkDuplicates.bam.bai"
    must_exist: false
    create_parent: true
    required: false
    direction: "output"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--metrics"
    description: "Duplicate metrics file generated by picard"
    info: null
    default:
    - "$id.MarkDuplicates.metrics.txt"
    must_exist: true
    create_parent: true
    required: false
    direction: "output"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  resources:
  - type: "bash_script"
    path: "script.sh"
    is_executable: true
  description: "Locate and tag duplicate reads in a BAM file\n"
  test_resources:
  - type: "bash_script"
    path: "test.sh"
    is_executable: true
  - type: "file"
    path: "testData/reference/genome.fasta"
  info:
    migration_info:
      git_repo: "https://github.com/nf-core/rnaseq.git"
      paths:
      - "modules/nf-core/picard/markduplicates/main.nf"
      - "modules/nf-core/picard/markduplicates/meta.yml"
      last_sha: "55398de6ab7577acfe9b1180016a93d7af7eb859"
  status: "enabled"
  requirements:
    commands:
    - "ps"
  set_wd_to_resources_dir: false
platforms:
- type: "docker"
  id: "docker"
  image: "ubuntu:22.04"
  target_organization: "data-intuitive"
  target_registry: "ghcr.io"
  namespace_separator: "/"
  resolve_volume: "Automatic"
  chown: true
  setup_strategy: "ifneedbepullelsecachedbuild"
  target_image_source: "https://github.com/data-intuitive/rnaseq.vsh"
  setup:
  - type: "docker"
    run:
    - "apt-get update && \\\napt-get install -y build-essential openjdk-17-jdk wget\
      \ && \\\nwget --no-check-certificate https://github.com/broadinstitute/picard/releases/download/3.1.0/picard.jar\
      \ && \\\nmv picard.jar /usr/local/bin \n"
    env:
    - "PICARD=/usr/local/bin/picard.jar"
  entrypoint: []
  cmd: null
- type: "nextflow"
  id: "nextflow"
  directives:
    tag: "$id"
  auto:
    simplifyInput: true
    simplifyOutput: false
    transcript: false
    publish: false
  config:
    labels:
      mem1gb: "memory = 1.GB"
      mem2gb: "memory = 2.GB"
      mem4gb: "memory = 4.GB"
      mem8gb: "memory = 8.GB"
      mem16gb: "memory = 16.GB"
      mem32gb: "memory = 32.GB"
      mem64gb: "memory = 64.GB"
      mem128gb: "memory = 128.GB"
      mem256gb: "memory = 256.GB"
      mem512gb: "memory = 512.GB"
      mem1tb: "memory = 1.TB"
      mem2tb: "memory = 2.TB"
      mem4tb: "memory = 4.TB"
      mem8tb: "memory = 8.TB"
      mem16tb: "memory = 16.TB"
      mem32tb: "memory = 32.TB"
      mem64tb: "memory = 64.TB"
      mem128tb: "memory = 128.TB"
      mem256tb: "memory = 256.TB"
      mem512tb: "memory = 512.TB"
      cpu1: "cpus = 1"
      cpu2: "cpus = 2"
      cpu5: "cpus = 5"
      cpu10: "cpus = 10"
      cpu20: "cpus = 20"
      cpu50: "cpus = 50"
      cpu100: "cpus = 100"
      cpu200: "cpus = 200"
      cpu500: "cpus = 500"
      cpu1000: "cpus = 1000"
  debug: false
  container: "docker"
info:
  config: "/home/nirmayi/data_intuitive/rnaseq.vsh/src/picard_markduplicates/config.vsh.yaml"
  platform: "docker"
  output: "/home/nirmayi/data_intuitive/rnaseq.vsh/target/docker/picard_markduplicates"
  executable: "/home/nirmayi/data_intuitive/rnaseq.vsh/target/docker/picard_markduplicates/picard_markduplicates"
  viash_version: "0.8.0-RC5"
  git_commit: "efa0ffd2fbdce950e208caa1570584b258689789"
  git_remote: "https://github.com/data-intuitive/rnaseq.vsh.git"
